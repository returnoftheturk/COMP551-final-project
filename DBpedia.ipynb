{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "from collections import Counter\n",
    "import string\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from numpy.random import random_integers\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy import sparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCsv(fileName):\n",
    "    fullFileName = r'C:\\Users\\Owner\\McGill\\4thYear\\COMP551\\final-project\\Datasets\\dbpedia_csv' + fileName\n",
    "    df = pd.read_csv(fullFileName, encoding='utf-8', header = None, names = ['y', 'title','desc'],\n",
    "                 sep=',')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = readCsv(r'\\train.csv')\n",
    "y_train = dfTrain['y']\n",
    "x_train = dfTrain.drop('y', axis=1)\n",
    "x_train = x_train[['title','desc']].apply(lambda x: ''.join(x), axis=1)\n",
    "\n",
    "dfTest = readCsv(r'\\test.csv')\n",
    "y_test = dfTest['y']\n",
    "x_test = dfTest.drop('y', axis=1)\n",
    "x_test = x_test[['title','desc']].apply(lambda x: ''.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicLen = 5000\n",
    "def createDictionary():\n",
    "    allWords = list()\n",
    "    cnt = Counter()\n",
    "    \n",
    "# Replacing !\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ with ' ' * 31 (31 spaces, needs to be same length)\n",
    "# and replacing ' with ' ' (apostrophe with space)\n",
    "    translator = str.maketrans(string.punctuation.replace('\\'', ''), 31*' ', '\\'')\n",
    "    \n",
    "    for i in range(0, len(x_train)):\n",
    "        allWords.extend(x_train.iloc[i].translate(translator).lower().split(\" \"))\n",
    "    \n",
    "    for word in allWords:\n",
    "        cnt[word] +=1\n",
    "    \n",
    "    dictionaryWords = list(zip(*cnt.most_common(dicLen + 1)[1:]))[0]\n",
    "    \n",
    "    dictionary = {}\n",
    "    for index, key in enumerate(dictionaryWords):\n",
    "        dictionary[key] = index\n",
    "#     print(dictionary)\n",
    "    newArray = np.asarray(cnt.most_common(dicLen + 1)[1:])\n",
    "    withIndexVocabArray = np.insert(newArray, 1, range(0,dicLen),1)\n",
    "    \n",
    "#     if trainingSet=='IMDB':\n",
    "#         toCsvDf('\\IMDB-vocab.txt', pd.DataFrame(withIndexVocabArray))\n",
    "#     elif trainingSet=='yelp':\n",
    "#         toCsvDf('\\yelp-vocab.txt', pd.DataFrame(withIndexVocabArray))\n",
    "        \n",
    "    return dictionary\n",
    "dictionary = createDictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertWordsToVector(trainingRow, dictionary, BOWType):\n",
    "    translator = str.maketrans(string.punctuation.replace('\\'', ''), 31*' ', '\\'')\n",
    "    returnRow = trainingRow.translate(translator).lower().split(\" \")\n",
    "    vector = np.zeros(len(dictionary), dtype = np.int8)\n",
    "    \n",
    "    for word in returnRow:\n",
    "        if word in dictionary:\n",
    "            if BOWType == 'BagOfWords':\n",
    "                vector[dictionary[word]] = np.int8(1)\n",
    "            elif BOWType == 'Frequency':\n",
    "                vector[dictionary[word]] += 1\n",
    "    \n",
    "    if BOWType == 'Frequency':\n",
    "#         To accomodate for the fact that one of the rows has one word, d-gust-ing, and the lenght of the vector is zero.\n",
    "#         Hence, the vector returns [Nan Nan Nan ... Nan Nan].  Now it returns [0 0 0 ... 0 0 0]\n",
    "        vectorLength =  np.sum(vector)\n",
    "        if vectorLength>0:\n",
    "            vector = np.divide(vector, vectorLength)\n",
    "            \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createBagOfWordsMatrix(df, dictionary, BOWType):\n",
    "    translator = str.maketrans(string.punctuation.replace('\\'', ''), 31*' ', '\\'')\n",
    "    \n",
    "    if BOWType == 'BagOfWords':\n",
    "        distancesArray = np.zeros((len(df), len(dictionary)), dtype = np.int8)\n",
    "    elif BOWType == 'Frequency':\n",
    "        distancesArray = np.zeros((len(df), len(dictionary)))\n",
    "        \n",
    "    for i in range(0, len(df)):\n",
    "        vector = convertWordsToVector(df.iloc[i], dictionary, BOWType)\n",
    "        distancesArray[i] = vector\n",
    "        \n",
    "    return distancesArray\n",
    "\n",
    "# print(createBagOfWordsMatrix(readTxt('\\yelp-train.txt'), createDictionary('yelp'), 'Frequency'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testScores(predicted, actual):\n",
    "    f1Score = f1_score(actual, predicted, average='macro')\n",
    "    accuracy = accuracy_score(actual, predicted)\n",
    "    confusionMatrix = confusion_matrix(actual, predicted)\n",
    "    print('F1 Score:', f1Score)\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Confusion Matrix:\\n', confusionMatrix)\n",
    "    return f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp\n",
      "{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}\n",
      "Training F1-Measure\n",
      "F1 Score: 0.941151126164\n",
      "Accuracy: 0.941294642857\n",
      "Confusion Matrix:\n",
      " [[35628   538   412    19    56   560   451   209     3    53    26   775\n",
      "    212  1058]\n",
      " [  336 38828    55    20    56    24   402   152     2    18     1     0\n",
      "      5   101]\n",
      " [  148    34 36575   201   798    14    44    32     1    55     2   808\n",
      "    292   996]\n",
      " [   18     3   382 39453    99     8     3     7     0     8     2     1\n",
      "      3    13]\n",
      " [  102    80   676   128 38749    50    47    49     0    49     0     0\n",
      "     10    60]\n",
      " [ 1131    21    14    21     4 38402   142   104     0    50     2     8\n",
      "     39    62]\n",
      " [ 1099  1895   122    19   101   164 34936  1426    20    60     5     4\n",
      "     14   135]\n",
      " [   55    30     4     3     4    76   483 39148    11   104    36     2\n",
      "      1    43]\n",
      " [   32   455     5     1    16     4   492  1565 37403     4     1     0\n",
      "      1    21]\n",
      " [   25     7    96   479    37    28    17    66     0 36373  2788     0\n",
      "      3    81]\n",
      " [  146     4    12     4     0    15    28    33     0  3596 36089     4\n",
      "      2    67]\n",
      " [   17     0   178     3     0     2     3    10     0    14     1 39498\n",
      "    200    74]\n",
      " [   78    11   115     5     8    27     5    12     0     4     0   270\n",
      "  38933   532]\n",
      " [  816   112   272     8    50    25    36    45     0    20    10   102\n",
      "   1394 37110]]\n",
      "Test F1-Measure\n",
      "F1 Score: 0.940097331075\n",
      "Accuracy: 0.940228571429\n",
      "Confusion Matrix:\n",
      " [[4450   69   46    4   15   80   52   23    0    4    2  102   21  132]\n",
      " [  62 4850    5    3   10    2   46   13    0    1    0    0    0    8]\n",
      " [  26    2 4548   23   95    0    2    0    0    8    0  110   36  150]\n",
      " [   0    0   50 4918   14    7    0    0    0    6    0    0    2    3]\n",
      " [  12    8   90   24 4836   11    3    4    0    8    0    0    0    4]\n",
      " [ 140    1    3    2    2 4814   14   12    0    3    0    1    4    4]\n",
      " [ 126  230   10    0   14   21 4382  183    2   15    0    1    1   15]\n",
      " [   9    7    0    0    1    8   78 4873    2   11    8    0    0    3]\n",
      " [   3   45    2    0    5    1   54  202 4685    0    0    0    0    3]\n",
      " [   4    0   19   54    8    2    3    6    0 4554  342    0    0    8]\n",
      " [  24    0    3    0    0    1    4    3    0  488 4465    0    2   10]\n",
      " [   4    0   19    1    0    0    0    0    0    2    0 4937   25   12]\n",
      " [   7    2    8    0    1    1    1    1    0    2    0   29 4876   72]\n",
      " [ 115   16   26    1    9    2    3    2    0    6    0   11  181 4628]]\n"
     ]
    }
   ],
   "source": [
    "def bernoulliNB(dataset, BOWType):\n",
    "    print(dataset)\n",
    "#     dictionary = createDictionary()\n",
    "    x_train_matrix = sparse.csr_matrix(createBagOfWordsMatrix(x_train, dictionary, BOWType))\n",
    "    x_test_matrix = sparse.csr_matrix(createBagOfWordsMatrix(x_test, dictionary, BOWType))\n",
    "    \n",
    "    clf = BernoulliNB()\n",
    "    print(clf.get_params())\n",
    "    clf.fit(x_train_matrix, y_train)\n",
    "    \n",
    "    print('Training F1-Measure')\n",
    "    predictionsArray = clf.predict(x_train_matrix)\n",
    "    testScores(predictionsArray, y_train)\n",
    "    \n",
    "#     print('Validation F1-Measure')\n",
    "#     predictionsArray = clf.predict(createBagOfWordsMatrix(validDF, dictionary, BOWType))\n",
    "#     testScores(predictionsArray, validDF[1])\n",
    "    \n",
    "    print('Test F1-Measure')\n",
    "    predictionsArray = clf.predict(x_test_matrix)\n",
    "    testScores(predictionsArray, y_test)\n",
    "    \n",
    "bernoulliNB('yelp', 'BagOfWords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp\n",
      "{'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "Training F1-Measure\n",
      "F1 Score: 0.988685591834\n",
      "Accuracy: 0.988691071429\n",
      "Confusion Matrix:\n",
      " [[38717   253    95     4    34   124   391    20     1    16    10    30\n",
      "     30   275]\n",
      " [  177 39553     8     0    17     1   202    12     4     4     1     0\n",
      "      1    20]\n",
      " [  144    21 39089    40   330     3    38     2     1    11     3    60\n",
      "     45   213]\n",
      " [    3     1    44 39928    20     1     0     1     0     1     0     0\n",
      "      0     1]\n",
      " [   49    21   332    15 39549     2    16     2     0     4     1     0\n",
      "      2     7]\n",
      " [   87     4     3     0     1 39872    26     4     0     2     1     0\n",
      "      0     0]\n",
      " [  376   291    28     2    22    26 39128    84    11     4     4     0\n",
      "      2    22]\n",
      " [    5     5     0     0     0     2    43 39917    17     8     2     0\n",
      "      0     1]\n",
      " [    1    10     0     0     0     0    18    11 39958     1     0     0\n",
      "      0     1]\n",
      " [    3     2     2     0     2     4     2     9     0 39614   358     0\n",
      "      0     4]\n",
      " [   52     2     0     0     0     4     3     2     0   690 39244     0\n",
      "      0     3]\n",
      " [   13     1    43     0     2     2     0     1     0     1     0 39895\n",
      "     24    18]\n",
      " [   19     1    28     0     3     0     2     0     0     4     0    53\n",
      "  39793    97]\n",
      " [  213    13   152     1    14     7    26     3     1     2     3    28\n",
      "    127 39410]]\n",
      "Test F1-Measure\n",
      "F1 Score: 0.974002453172\n",
      "Accuracy: 0.974014285714\n",
      "Confusion Matrix:\n",
      " [[4719   45   14    4   16   38   61    7    3    7    4   19   14   49]\n",
      " [  46 4876    1    1   10    3   48    2    3    1    1    0    2    6]\n",
      " [  25   11 4760   20   64    0    7    2    0    5    2   29   27   48]\n",
      " [   4    1   23 4942   16    3    1    1    0    3    1    1    3    1]\n",
      " [  11   13   75   16 4860    7    5    3    1    3    0    1    3    2]\n",
      " [  48    2    2    0    4 4925   10    3    1    0    2    1    2    0]\n",
      " [  57   53    6    1    4   12 4792   34   13   15    0    2    3    8]\n",
      " [   3    3    0    1    4    3   28 4937   10    6    3    1    0    1]\n",
      " [   0    3    2    0    0    1    9   18 4965    0    0    0    1    1]\n",
      " [   4    0    1    0    0    0    1    7    0 4899   86    0    0    2]\n",
      " [  15    2    0    0    0    3    3    2    0  130 4845    0    0    0]\n",
      " [   6    0   23    1    0    1    2    0    0    0    0 4938   19   10]\n",
      " [  11    4   17    1    1    3    1    3    0    1    1   19 4894   44]\n",
      " [  38   10   35    0    8    3    5    2    1    4    2   13   50 4829]]\n",
      "Total time: 276.238043\n"
     ]
    }
   ],
   "source": [
    "def linearSVC(dataset, BOWType):\n",
    "    print(dataset)\n",
    "#     dictionary = createDictionary()\n",
    "    x_train_matrix = sparse.csr_matrix(createBagOfWordsMatrix(x_train, dictionary, BOWType))\n",
    "    x_test_matrix = sparse.csr_matrix(createBagOfWordsMatrix(x_test, dictionary, BOWType))\n",
    "    \n",
    "    t0 = time.time()\n",
    "    clf = LinearSVC()\n",
    "    print(clf.get_params())\n",
    "    clf.fit(x_train_matrix, y_train)\n",
    "    \n",
    "    print('Training F1-Measure')\n",
    "    predictionsArray = clf.predict(x_train_matrix)\n",
    "    testScores(predictionsArray, y_train)\n",
    "    \n",
    "#     print('Validation F1-Measure')\n",
    "#     predictionsArray = clf.predict(createBagOfWordsMatrix(validDF, dictionary, BOWType))\n",
    "#     testScores(predictionsArray, validDF[1])\n",
    "    \n",
    "    print('Test F1-Measure')\n",
    "    predictionsArray = clf.predict(x_test_matrix)\n",
    "    testScores(predictionsArray, y_test)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print('Total time: %f' %(t1-t0))\n",
    "    \n",
    "linearSVC('yelp', 'BagOfWords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 10.000000\n"
     ]
    }
   ],
   "source": [
    "t0 = 10\n",
    "t1 = 20\n",
    "print('total time %f' %(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterateBernoulliNB(dataset, BOWType):\n",
    "    print(dataset)\n",
    "    print(BOWType)\n",
    "    if dataset == 'yelp':\n",
    "        dictionary = createDictionary('yelp')\n",
    "        trainingDF = readTxt('\\yelp-train.txt')\n",
    "        validDF = readTxt('\\yelp-valid.txt')\n",
    "        testDF = readTxt('\\yelp-test.txt')\n",
    "    elif dataset == 'IMDB':\n",
    "        dictionary = createDictionary('IMDB')\n",
    "        trainingDF = readTxt('\\IMDB-train.txt')\n",
    "        validDF = readTxt('\\IMDB-valid.txt')\n",
    "        testDF = readTxt('\\IMDB-test.txt')\n",
    "    \n",
    "    trainingDataMatrix = createBagOfWordsMatrix(trainingDF, dictionary, BOWType)\n",
    "    validDataMatrix = createBagOfWordsMatrix(validDF, dictionary, BOWType)\n",
    "    testDataMatrix = createBagOfWordsMatrix(testDF, dictionary, BOWType)\n",
    "    targetVectorTraining = trainingDF[1]\n",
    "    targetVectorValid = validDF[1]\n",
    "    targetVectorTest = testDF[1]\n",
    "    \n",
    "    alphaLinspace = np.linspace(0.000001, 0.5, 40)\n",
    "    f1Scores = list()\n",
    "    \n",
    "#     tuning parameters with validation set\n",
    "    for alpha in alphaLinspace:\n",
    "        clf = BernoulliNB(alpha = alpha)\n",
    "        clf.fit(trainingDataMatrix, targetVectorTraining)\n",
    "        predictionsArray = clf.predict(validDataMatrix)\n",
    "        f1Score = testScores(predictionsArray, targetVectorValid)\n",
    "#         print(f1Score)\n",
    "        f1Scores.append(f1Score)\n",
    "    \n",
    "    plt.figure(figsize=(20,8), dpi=80)\n",
    "    plt.plot(alphaLinspace, f1Scores)\n",
    "    plt.axvline(x=alphaLinspace[np.argmax(f1Scores)],linestyle='dashed')\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.ylabel('F1-Measure')\n",
    "    plt.title('F1-Measure Validation')\n",
    "    plt.show()\n",
    "\n",
    "    bestF1Alpha = alphaLinspace[np.argmax(f1Scores)]\n",
    "    print('Best Alpha for F1-Measure ', bestF1Alpha)\n",
    "    print('MAX F1-Measure ', max(f1Scores))\n",
    "    \n",
    "#     final Test F1-Measure\n",
    "    \n",
    "    clf = BernoulliNB(alpha = bestF1Alpha)\n",
    "    clf.fit(trainingDataMatrix, targetVectorTraining)\n",
    "    testPredictionsArray = clf.predict(testDataMatrix)\n",
    "    testF1Score = testScores(testPredictionsArray, targetVectorTest)\n",
    "    print('F1 Score for Testing at Alpha = {0} is {1}'.format(bestF1Alpha, testF1Score))\n",
    "    \n",
    "    return alphaLinspace[np.argmax(f1Scores)]\n",
    "\n",
    "    \n",
    "        \n",
    "# iterateBernoulliNB('IMDB', 'Frequency')\n",
    "# iterateBernoulliNB('IMDB', 'BagOfWords')\n",
    "# iterateBernoulliNB('IMDB', 'Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp Random Classifier\n",
      "{'constant': None, 'random_state': None, 'strategy': 'uniform'}\n",
      "Training F1-Measure\n",
      "F1 Score: 0.0717236247768\n",
      "Confusion Matrix:\n",
      " [[2856 2963 2860 2904 2894 2873 2831 2849 2771 2732 2852 2838 2877 2900]\n",
      " [2798 2793 2845 2962 2894 2863 2971 2809 2838 2838 2866 2870 2810 2843]\n",
      " [2900 2944 2908 2797 2862 2780 2866 2816 2916 2823 2851 2776 2858 2903]\n",
      " [2886 2842 2859 2763 2804 2828 2890 2828 2907 2885 2919 2880 2885 2824]\n",
      " [2793 2919 2851 2891 2907 2854 2839 2812 2902 2800 2798 2895 2890 2849]\n",
      " [2836 2897 2834 2873 2837 2851 2953 2833 2860 2829 2851 2884 2829 2833]\n",
      " [2893 2942 2905 2790 2776 2876 2851 2834 2851 2784 2874 2874 2882 2868]\n",
      " [2827 2778 2893 2866 2847 2855 2875 2857 2891 2894 2847 2797 2906 2867]\n",
      " [2828 2812 2827 2828 2848 2866 2887 2884 2939 2779 2845 2933 2900 2824]\n",
      " [2850 2811 2917 2806 2910 2909 2860 2927 2863 2796 2882 2807 2825 2837]\n",
      " [2899 2848 2905 2823 2957 2888 2857 2845 2844 2761 2899 2838 2825 2811]\n",
      " [2828 2822 2838 2865 2842 2743 2912 2956 2902 2949 2818 2850 2839 2836]\n",
      " [2884 2975 2867 2848 2776 2758 2881 2840 2824 2806 2927 2822 2969 2823]\n",
      " [2871 2846 2849 2812 2842 2809 2881 2776 2864 2868 2859 2819 2977 2927]]\n",
      "Test F1-Measure\n",
      "F1 Score: 0.0708474984903\n",
      "Confusion Matrix:\n",
      " [[384 326 360 382 363 323 355 343 343 359 373 354 376 359]\n",
      " [379 305 375 354 346 366 387 363 333 359 364 362 348 359]\n",
      " [343 343 348 359 337 359 360 360 379 344 371 381 369 347]\n",
      " [337 383 344 375 347 339 354 394 345 365 379 345 364 329]\n",
      " [353 389 366 352 343 325 318 374 354 362 351 372 385 356]\n",
      " [361 355 376 378 375 366 348 351 369 361 338 343 339 340]\n",
      " [358 338 362 396 346 330 349 368 369 363 338 369 368 346]\n",
      " [369 331 350 335 354 335 341 402 366 340 355 376 384 362]\n",
      " [337 354 380 373 324 359 377 373 328 358 367 335 365 370]\n",
      " [341 335 363 365 366 349 313 400 385 362 352 339 376 354]\n",
      " [405 334 347 398 353 356 361 361 341 362 330 354 353 345]\n",
      " [349 356 375 324 368 360 363 332 354 364 361 368 363 363]\n",
      " [366 343 337 371 363 353 346 347 337 378 329 400 360 370]\n",
      " [356 373 379 350 331 358 324 368 387 339 329 399 366 341]]\n"
     ]
    }
   ],
   "source": [
    "def randomClassifier(dataset, BOWType):\n",
    "    print(dataset, 'Random Classifier')\n",
    "    \n",
    "    clf = DummyClassifier(strategy='uniform')\n",
    "    print(clf.get_params())\n",
    "    clf.fit(createBagOfWordsMatrix(x_train, dictionary, BOWType), y_train)\n",
    "    \n",
    "    print('Training F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(x_train, dictionary, BOWType))\n",
    "    testScores(predictionsArray, y_train)\n",
    "    \n",
    "#     print('Validation F1-Measure')\n",
    "#     predictionsArray = clf.predict(createBagOfWordsMatrix(validDF, dictionary, BOWType))\n",
    "#     testScores(predictionsArray, validDF[1])\n",
    "    \n",
    "    print('Test F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(x_test, dictionary, BOWType))\n",
    "    testScores(predictionsArray, y_test)\n",
    "    \n",
    "randomClassifier('yelp', 'BagOfWords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
